{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data_exploration\"></a>\n",
    "# 1. Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is available in the */data* folder. The database structure is freely inspired from the AP-HP Clinical Data Warehouse (CDW).\n",
    "\n",
    "Let's assume that data were extracted from the CDW on **December 1st, 2025**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: a first illustration of Real-World Data (RWD) analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this first exercise we introduce some basic categories of RWD and we illustrate some of the challenges related to their preprocessing for research.\n",
    "\n",
    "We initialize the notebook by importing the following libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization library\n",
    "import altair as alt\n",
    "alt.data_transformers.enable('default', max_rows=None)\n",
    "\n",
    "# Dates management\n",
    "import datetime\n",
    "\n",
    "# For the computation of Kaplan-Meier estimates and log-rank tests\n",
    "import lifelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Data Exploration](#data_exploration)  \n",
    "    1.1 [Patients' identities and demographic data](#patient_ids)  \n",
    "    1.2 [Administrative data related to patients' pathways](#visits)  \n",
    "    1.3 [Claim data related to patients' conditions (diagnosis)](#cond)  \n",
    "    1.4 [Structured medication data](#med)  \n",
    "2. [Preprocessing](#preprocessing)  \n",
    "    2.1 [First attempt of visualizing survival curves](#first_kaplan)  \n",
    "    2.2 [Pre-processing patients' identities and demographic data](#prepro_patient)  \n",
    "    2.3 [Pre-processing administrative data related to patients' pathways](#prepro_visits)  \n",
    "    2.4 [Pre-processing claim data](#prepro_cond)  \n",
    "3. [Statistical analysis](#stat)  \n",
    "    3.1 [First objective : Are the drugs efficient on the overall population ?](#stat_first_kaplan)  \n",
    "    3.2 [Second objective : Sub-population analysis](#stat_second_kaplan)  \n",
    "4. [Takeaways](#takeaways) \n",
    "5. [References](#references)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data_exploration\"></a>\n",
    "# 1. Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is available in the */data* folder. The database structure is freely inspired from the AP-HP Clinical Data Warehouse (CDW).\n",
    "\n",
    "Let's assume that data were extracted from the CDW on **December 1st, 2025**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"patient_ids\"></a>\n",
    "## 1.1 Patients' identities and demographic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Open the *data/df_person.pkl* file using the `pandas.read_pickle()` function.\n",
    "- Explore the type of each feature of the `df_person` DataFrame with the `.info()` function.\n",
    "- Check out the first rows of the DataFrame using the `.head()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_person = #TODO\n",
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many patient_ids do we have in this database ?\n",
    "\n",
    "TIP : You can use the `DataFrame.col_name.unique()` function on one of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"We have {#TODO} unique patient ids in this dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"visits\"></a>\n",
    "## 1.2 Administrative data related to patients' pathways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore the `df_visit` DataFrame that gathers administrative data about patient's hospitalizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_visit = #TODO\n",
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the number of visits recorded by care site.\n",
    "\n",
    "TIP : You can use the `DataFrame.col_name.value_counts()`function on the right column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cond\"></a>\n",
    "## 1.3 Claim data related to patients' conditions (diagnosis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore the `df_condition` DataFrame that gathers claim data used by hospital managers for reimbursement purposes.\n",
    "\n",
    "Meeting with experts has allowed us to identify the ICD-10 codes corresponding to the flu virus :\n",
    "- J09\n",
    "- J10\n",
    "- J11\n",
    "\n",
    "You can check out on the following website the meaning of those codes : https://www.aideaucodage.fr/cim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_condition = #TODO\n",
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many ICD-10 codes can you identify in this dataset ?  \n",
    "\n",
    "TIP : You can use the `DataFrame.col_name.unique()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The available ICD-10 codes are the following : {#TODO}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"med\"></a>\n",
    "## 1.4 Structured medication data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore the `df_med` DataFrame gathering structured data in regards to medication administration during hospital stays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_med = nfhlaefhkzl\n",
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"preprocessing\"></a>\n",
    "# 2. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know what categories of data are available, let's process them!\n",
    "\n",
    "We have defined two helper functions in the *viz.py* script that leverage the [*lifelines*](https://lifelines.readthedocs.io/en/latest/) library to plot Kaplan-Meier estimates and compute log-rank tests relatively to our objectives :  \n",
    "1. Evaluate the overall impact of drug A and B\n",
    "2. Stratify our analysis on age and gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the helper functions\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from viz import plot_primary_kaplan, plot_secondary_kaplan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"first_kaplan\"></a>\n",
    "## 2.1 First attempt of visualizing survival curves"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to compute straightforwardly the Kaplan-Meier estimates!  \n",
    "\n",
    "First define the end date of the study, as needed to censor data, using the [*datetime*](https://pypi.org/project/DateTime/) package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_end_of_study = #TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the docstrings of the `plot_primary_kaplan` function, and use them to plot the first Kaplan-Meier estimates for the whole population regarding the drug administration.\n",
    "\n",
    "TIP : To print the documentation of a function, you can call the `__doc__`attribute of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(#TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_primary_kaplan(#TODO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the Kaplan-Meier estimates seem correct ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"prepro_patient\"></a>\n",
    "## 2.2 Pre-processing patients' identities and demographic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Birth dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore identities and demographic data. Count the number of missing values for each feature of the `df_person` DataFrame. What do you observe ?\n",
    "\n",
    "TIP : Use the `DataFrame.isna().sum()` function to compute the number of NA values within each column of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_person.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some dates of birth are missing. Can you search for the origin of this lack of data ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TIP : Check out the impact of `cdm_source` in the missingness of birth datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of missing birth datetimes for EHR 1 : {#TODO}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of missing birth datetimes for EHR 2 : {#TODO}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What would you suggest to address this bias ?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Correction** :  \n",
    "The birth dates quality issue can be directly associated to the registration within the \"EHR 2\" software. Although it could include a clinical bias, a solution may be to discard data coming from this software (this assumption should be grounded in an understanding of the context of use of both softwares! Clinicians' expertise shall be leveraged to confirm/infirm this assumption)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `df_person_fix` DataFrame that contains patient information coming from `cdm_source` other than \"EHR 2\".\n",
    "\n",
    "TIP : \n",
    "You can use the `query` built-in function : \n",
    "```python \n",
    "df_condition.query(\"content of your query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_person_fix = #TODO\n",
    "df_person_fix.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have handled the missingness of dates of birth, let's check the plausibility of the available dates. Plot the birth datetime distribution as a bar chart.\n",
    "\n",
    "Tip 1 : you can convert the birth datetime to a \"YYYY-MM\" format using the following command : \n",
    "```python \n",
    "    df_person_fix['birth_date'] = df_person_fix['birth_datetime'].dt.strftime('%Y-%m')\n",
    "```  \n",
    "Tip 2 : If your DataFrame contains too many rows, you can use the `pandas.DataFrame.groupby()` function and count the number of `person_id` by `birth_date`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_person_fix['birth_date'] = #TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "birth_dates_summary = #TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you see ? Does this distribution look normal ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Death dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the death datetime distribution. Do you observe anything seeming abnormal ?\n",
    "\n",
    "TIP : Use the same steps than for the birth datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_person_fix['death_date'] = #TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "death_dates_summary = #TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you observe ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"prepro_visits\"></a>\n",
    "## 2.3 Pre-processing administrative data related to patients' pathways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider now administrative data related to patients' hospitalizations.\n",
    "\n",
    "Plot the distribution of entrance dates : column \"visit_start_datetime\" of the *df_visit* DataFrame.  \n",
    "\n",
    "Tip 1: Check out the presence of null dates, and convert dates to the \"YYYY-MM\" format.  \n",
    "Tip 2: If your DataFrame contains to many rows, you can use the `pandas.DataFrame.groupby()` function and count the number of `person_id` by `visit_start_date`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_visit['visit_start_date'] = #TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visit_start_dates_summary = #TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discard visits which dates are not plausible (*e.g* occurring before 01/01/2000), and checkout for the new date repartition.\n",
    "\n",
    "TIPS : \n",
    "- Use  `pd.to_datetime(\"01/01/2000\"))` to compare visit start date to 01/01/2000 and create a Dataframe `df_visit_fix` with only visits starting after 01/01/2000.\n",
    "- Convert the visit start datetime to a \"YYYY-MM\" format\n",
    "- Use the `pandas.DataFrame.groupby()` function and count the number of `person_id` by `birth_date`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_visit_fix = #TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_visit_fix['visit_start_date'] = #TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visit_fix_start_dates_summary = #TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WARNING** : although knowing the temporality of a visit is crucial to estimate survival functions, do not forget that this selection may once more induce biases. We will evaluate its impact later on in the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"prepro_cond\"></a>\n",
    "## 2.4 Pre-processing claim data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider now claim data. We want to plot the total amount of visits related to flu treatment, and their temporal repartition.  \n",
    "\n",
    "Create a `df_cond_fix` DataFrame that contains only information about the previously selected visits.  \n",
    "\n",
    "Tip 1 : Merge the `df_cond` and `df_visit_fix` DataFrames on their common feature *visit_occurrence_id*.\n",
    "\n",
    "Tip 2 : we only need the *visit_start_date* and *visit_occurrence_id* from the `df_visit_fix` DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cond_fix = #TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cond_fix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cond_fix[\"visit_start_date\"] = #TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the temporal repartition of *visit_occurrence_id* counts for each *condition_source_value*.\n",
    "\n",
    "Tip : you can group the `df_cond_fix` DataFrame by *visit_start_date* and *condition_source_value*, and count the number of *visit_occurrence_id* for each group, using the following command :\n",
    "```python\n",
    " DataFrame.groupby(['key1', 'key2'], as_index=False).visit_occurrence_id.count()\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_fix_start_dates_summary = #TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_fix_start_dates_summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you observe ?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an `is_epidemic` column in the `df_cond_fix` DataFrame to detect conditions linked to the flu epidemic, using it associated codes (J09, J10, J11).\n",
    "\n",
    "Tip 1 : Create a `list_epidemic_icd10` gathering the epidemic codes.  \n",
    "TIP 2: You can use the `df_cond_fix.condition_source_value.apply()` function, and detect if each element of the column is in the `list_epidemic_icd10`. The argument can be a function of type :\n",
    "``` python\n",
    "lambda x: treatment(x)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_epidemic_icd10 = #TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cond_fix[\"is_epidemic\"] = #TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `epidemic_cond_summary` DataFrame gathering the number of epidemic vs non-epidemic visits by `condition_start_date`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epidemic_cond_summary = #TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epidemic_cond_summary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the temporal repartition of epidemic visits compared to non-epidemic visits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"stat\"></a>\n",
    "# 3. Statistical analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have pre-processed raw data to correct flawed or missing values and to define research-oriented variables, we can conduct the statistical analysis. Our data is ready to plot the Kaplan-Meier estimates of survival curves, and realize the log-rank tests.  \n",
    "We are only interested in epidemic visits, so filter out non epidemic conditions in the `df_cond_fix` DataFrame, and deduce from it the `df_visit_epidemic` DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cond_epidemic = #TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_visit_epidemic = #TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"stat_first_kaplan\"></a>\n",
    "### 3.1 First objective : Are the drugs efficient on the overall population ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the new primary Kaplan-Meier estimates for the whole `df_person_fix` DataFrame with regards to the epidemic conditions, newly fixed visits and drug administration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_primary_kaplan(#TODO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you observe ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"stat_second_kaplan\"></a>\n",
    "### 3.2 Second objective : Sub-population analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reach our secondary objective, we now conduct the same statistical analysis on sub-populations that correspond to different sexes and ages  in order to obtain a better insight on drugs' efficiencies.  \n",
    "\n",
    "Plot the secondary Kaplain-Meier estimates for the sub-group analysis on **cohort A**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_secondary_kaplan(#TODO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the secondary Kaplain-Meier estimates for the sub-group analysis on **cohort B**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_secondary_kaplan(#TODO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can you conclude from this subgroup analyses ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analysis presented in this notebook is obviously not representative of a real research study that usually comprises more data transformations and a more involved statistical design. In particular, we have not considered the biases that may be induced by discarding missing data although it is a crucial issue that may be addressed leveraging complex statistical methodologies. This notebook aims only at providing a first illustration of some challenges related to the analysis of Real-World Data provided in hospitals' clinical data warehouses. \n",
    "\n",
    "In particular, it shows that analysis pipelines suited to Real-World Data studies are complex and multistage. Consolidating the quality of preprocessing pipelines appears important to enhance the reliability of evidences produced on EHR data. This consolidation may be reached by opening the code of the analysis pipelines to review, and by developing and testing it collaboratively for instance as part of open source scientific libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"takeaways\"></a>\n",
    "# 4. Takeaways\n",
    "\n",
    "- **Real-World Data verifies the no pain, no gain** principle. Although data may appear simpler to collect than in a randomized controlled trial, reaching meaningful insights requires correcting numerous biases and applying important transformations to raw data.\n",
    "- **Administrative and claim data** comprises important information for research although its has not been collected for that purpose.\n",
    "- **The analysis pipelines required to analyse Real-World Data are complex** and rely on numerous transformations that progressively improve data quality and its suitability for research. Sharing the development of analysis pipelines among projects, for instance in scientific libraries, improves the overall efficiency and quality of research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"references\"></a>\n",
    "# 5. References\n",
    "\n",
    "- Kohane, Isaac S, Bruce J Aronow, Paul Avillach, Brett K Beaulieu-Jones, Riccardo Bellazzi, Robert L Bradford, Gabriel A Brat, et al. « What Every Reader Should Know About Studies Using Electronic Health Record Data but May Be Afraid to Ask ». Journal of Medical Internet Research 23, nᵒ 3 (2 mars 2021): e22219. https://doi.org/10.2196/22219.\n",
    "- Kaplan, E. L., et Paul Meier. « Nonparametric Estimation from Incomplete Observations ». Journal of the American Statistical Association 53, nᵒ 282 (1958): 457‑81. https://doi.org/10.2307/2281868.\n",
    "- Davidson-Pilon, Cameron. lifelines, survival analysis in Python. Zenodo, 2021. https://doi.org/10.5281/zenodo.5745573.\n",
    "- McCoy, Allison B, Adam Wright, Michael G Kahn, Jason S Shapiro, Elmer Victor Bernstam, et Dean F Sittig. « Matching Identifiers in Electronic Health Records: Implications for Duplicate Records and Patient Safety ». BMJ Quality & Safety 22, nᵒ 3 (mars 2013): 219‑24. https://doi.org/10.1136/bmjqs-2012-001419.\n",
    "- Wilson, Greg, D. A. Aruliah, C. Titus Brown, Neil P. Chue Hong, Matt Davis, Richard T. Guy, Steven H. D. Haddock, et al. « Best Practices for Scientific Computing ». Édité par Jonathan A. Eisen. PLoS Biology 12, nᵒ 1 (7 janvier 2014): e1001745. https://doi.org/10.1371/journal.pbio.1001745."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2ffb0fb47ea8f733c001ba519ad88900dd17f4bfc9ebfd0d356a457e5cc19a15"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('eds-tuto')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
